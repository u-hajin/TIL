## 목차

- 4.0 [구조적 API 개요](#40-구조적-api-개요)
- 4.1 [DataFrame과 Dataset](#41-dataframe과-dataset)

## 4.0 구조적 API 개요

구조적 API는 비정형 로그 파일, 반정형 CSV 파일, 정형적인 파케이(Parquet) 파일까지 다양한 유형의 데이터를 처리할 수 있다.

구조적 API에는 다음과 같은 세 가지 분산 컬렉션 API가 있다.

- **Dataset**

- **DataFrame**

- **SQL 테이블과 뷰**

**배치**(**batch**)와 **스트리밍**(**streaming**) 처리에서 구조적 API를 사용할 수 있다. 구조적 API 활용 시

**배치 작업** $\rightarrow$ **스트리밍 작업**, **스트리밍 작업** $\rightarrow$ **배치 작업** 변환이 가능하다.

구조적 API는 데이터 흐름을 정의하는 기본 추상화 개념으로, 이 장에서는 반드시 이해해야 하는 세 가지 기본 개념을 설명한다.

- **타입형(typed) / 비타입형(untyped) API의 개념과 차이점**

- **핵심 용어**

- **스파크가 구조적 API의 데이터 흐름을 해석하고 클러스터에서 실행하는 방식**

> NOTE\_ 스파크의 기본 개념과 정의를 다시 한번 생각한다. 스파크는 **트랜스포메이션**의 처리 과정을 정의하는 분산 프로그래밍 모델이다.
>
> 사용자가 정의한 다수의 트랜스포메이션은 지향성 비순환 그래프(DAG)로 표현되는 명령을 만들어낸다. 액션은 하나의 잡을 클러스터에서 실행하기 위해 스테이지와 태스크로 나누고 DAG 처리 프로세스를 실행한다.
>
> 트랜스포메이션과 액션으로 다루는 논리적 구조가 DataFrame, Dataset이다.  
> 새로운 DataFrame, Dataset을 생성하려면 트랜스포메이션을 호출해야 한다. 그리고 연산을 시작하거나 사용 언어에 맞는 데이터 타입으로 변환하려면 액션을 호출해야 한다.

## 4.1 DataFrame과 Dataset

스파크는 DataFrame과 Dataset이라는 두 가지 구조화된 컬렉션 개념을 가지고 있다.  
둘 사이의 의미적인 차이점을 알아보기 전에 무엇을 나타내는지 먼저 정의한다.

- 잘 정의된 로우와 컬럼을 가지는 분산 테이블 형태의 컬렉션

  $\rightarrow$ 각 컬럼은 다른 컬럼과 동일한 수의 로우 가짐('값 없음'은 null로 표시)

  $\rightarrow$ 컬렉션의 모든 로우는 같은 데이터 타입 정보 가지고 있음

- 결과를 생성하기 위해 어떤 데이터에 어떤 연산을 적용해야 하는지 정의하는 지연 연산의 실행 계획이며, 불변성 가짐

  $\rightarrow$ DataFrame에 액션 호출 시 스파크는 트랜스포메이션을 실제 실행하고 결과 반환

  $\rightarrow$ 이 과정은 사용자가 원하는 결과를 얻기 위해 로우와 컬럼을 처리하는 방법에 대한 계획을 나타냄

기본적으로 테이블과 뷰는 DataFrame과 같다. 대신 테이블은 DataFrame 코드 대신 SQL을 사용한다.

DataFrame과 Dataset을 더 구체적으로 정의하려면 '스키마'를 알아야 한다.  
스키마는 분산 컬렉션에 저장할 데이터 타입을 정의하는 방법이다.
